<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://zhipengy.com//feed.xml" rel="self" type="application/atom+xml"/><link href="https://zhipengy.com//" rel="alternate" type="text/html" hreflang="en"/><updated>2026-01-22T08:13:16+00:00</updated><id>https://zhipengy.com//feed.xml</id><title type="html">Zhipeng Yin</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Fairness in Large Language Models:A Tutorial</title><link href="https://zhipengy.com//blog/2025/ICDMFairness/" rel="alternate" type="text/html" title="Fairness in Large Language Models:A Tutorial"/><published>2025-11-17T00:00:00+00:00</published><updated>2025-11-17T00:00:00+00:00</updated><id>https://zhipengy.com//blog/2025/ICDMFairness</id><content type="html" xml:base="https://zhipengy.com//blog/2025/ICDMFairness/"><![CDATA[<h3 id="abstract">Abstract</h3> <p>Large Language Models (LLMs) have demonstrated remarkable success across various domains over the years. However, despite their promising performance on various real world tasks, most of these algorithms lack fairness considerations, potentially leading to discriminatory outcomes against marginalized demographic groups and individuals. Many recent publications have explored ways to mitigate bias in LLMs. Nevertheless, a comprehensive understanding of the root causes of bias, their effects, and possible limitations of LLMs from the perspective of fairness is still in its early stages. To bridge this gap, this tutorial provides a systematic overview of recent advances in fair LLMs, beginning with real-world case studies, followed by an analysis of bias causes. We then explore fairness concepts specific to LLMs, summarizing bias evaluation strategies and algorithms designed to promote fairness. Finally, we analyze bias in LLM datasets and discuss current research challenges and open questions in the field.</p> <h3 id="authors">Authors</h3> <p>Zichong Wang, <code class="language-plaintext highlighter-rouge">Zhipeng Yin</code>, Avash Palikhe and Wenbin Zhang</p> <h3 id="website">Website</h3> <p><a href="https://fairness-lms-tutorial.github.io/">Click</a> to visit our tutorial website.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Tutorial, 2025 IEEE International Conference on Data Mining (ICDM), Washington, D.C., United States]]></summary></entry><entry><title type="html">Uncertain Boundaries:A Tutorial on Copyright Challenges and Cross-Disciplinary Solutions for Generative AI</title><link href="https://zhipengy.com//blog/2025/CIKMCopyright/" rel="alternate" type="text/html" title="Uncertain Boundaries:A Tutorial on Copyright Challenges and Cross-Disciplinary Solutions for Generative AI"/><published>2025-11-16T00:00:00+00:00</published><updated>2025-11-16T00:00:00+00:00</updated><id>https://zhipengy.com//blog/2025/CIKMCopyright</id><content type="html" xml:base="https://zhipengy.com//blog/2025/CIKMCopyright/"><![CDATA[<h3 id="abstract">Abstract</h3> <p>As generative artificial intelligence (AI) becomes increasingly prevalent in creative industries, intellectual property issues have come to the forefront, especially regarding AI-generated content that closely resembles human-created works. Recent high-profile incidents involving AI-generated outputs reproducing copyrighted materials underscore the urgent need to reassess current copyright frameworks and establish effective safeguards against infringement. To this end, this tutorial provides a structured overview of copyright challenges in generative AI across the entire development lifecycle. It begins by outlining key copyright principles relevant to generative models, then explores methods for detecting and evaluating potential infringement in generated outputs. The session also introduces strategies to safeguard creative content and training data from unauthorized replication, including mitigation techniques during model training. Finally, it reviews existing regulatory frameworks, highlights unresolved research questions, and offers recommendations to guide future work in this evolving area.</p> <h3 id="authors">Authors</h3> <p><code class="language-plaintext highlighter-rouge">Zhipeng Yin</code>, Zichong Wang, Avash Palikhe and Wenbin Zhang</p> <h3 id="website">Website</h3> <p><a href="https://aicopyright-tutorial.github.io/">Click</a> to visit our tutorial website.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Tutorial, The ACM International Conference on Information and Knowledge Management (CIKM), Seoul, Korea]]></summary></entry><entry><title type="html">Fairness in Large Language Models:A Tutorial</title><link href="https://zhipengy.com//blog/2025/CIKMFairness/" rel="alternate" type="text/html" title="Fairness in Large Language Models:A Tutorial"/><published>2025-11-15T00:00:00+00:00</published><updated>2025-11-15T00:00:00+00:00</updated><id>https://zhipengy.com//blog/2025/CIKMFairness</id><content type="html" xml:base="https://zhipengy.com//blog/2025/CIKMFairness/"><![CDATA[<h3 id="abstract">Abstract</h3> <p>Large Language Models (LLMs) have demonstrated remarkable success across various domains over the years. However, despite their promising performance on various real world tasks, most of these algorithms lack fairness considerations, potentially leading to discriminatory outcomes against marginalized demographic groups and individuals. Many recent publications have explored ways to mitigate bias in LLMs. Nevertheless, a comprehensive understanding of the root causes of bias, their effects, and possible limitations of LLMs from the perspective of fairness is still in its early stages. To bridge this gap, this tutorial provides a systematic overview of recent advances in fair LLMs, beginning with real-world case studies, followed by an analysis of bias causes. We then explore fairness concepts specific to LLMs, summarizing bias evaluation strategies and algorithms designed to promote fairness. Finally, we analyze bias in LLM datasets and discuss current research challenges and open questions in the field.</p> <h3 id="authors">Authors</h3> <p>Zichong Wang, <code class="language-plaintext highlighter-rouge">Zhipeng Yin</code>, Avash Palikhe and Wenbin Zhang</p> <h3 id="website">Website</h3> <p><a href="https://fairness-lms-tutorial.github.io/">Click</a> to visit our tutorial website.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Tutorial, The ACM International Conference on Information and Knowledge Management (CIKM), Seoul, Korea]]></summary></entry><entry><title type="html">Fairness in Large Language Models:A Tutorial</title><link href="https://zhipengy.com//blog/2025/IJCAIFairness/" rel="alternate" type="text/html" title="Fairness in Large Language Models:A Tutorial"/><published>2025-08-16T00:00:00+00:00</published><updated>2025-08-16T00:00:00+00:00</updated><id>https://zhipengy.com//blog/2025/IJCAIFairness</id><content type="html" xml:base="https://zhipengy.com//blog/2025/IJCAIFairness/"><![CDATA[<h3 id="abstract">Abstract</h3> <p>Large Language Models (LLMs) have demonstrated remarkable success across various domains over the years. However, despite their promising performance on various real world tasks, most of these algorithms lack fairness considerations, potentially leading to discriminatory outcomes against marginalized demographic groups and individuals. Many recent publications have explored ways to mitigate bias in LLMs. Nevertheless, a comprehensive understanding of the root causes of bias, their effects, and possible limitations of LLMs from the perspective of fairness is still in its early stages. To bridge this gap, this tutorial provides a systematic overview of recent advances in fair LLMs, beginning with real-world case studies, followed by an analysis of bias causes. We then explore fairness concepts specific to LLMs, summarizing bias evaluation strategies and algorithms designed to promote fairness. Finally, we analyze bias in LLM datasets and discuss current research challenges and open questions in the field.</p> <h3 id="authors">Authors</h3> <p>Zichong Wang, Avash Palikhe, <code class="language-plaintext highlighter-rouge">Zhipeng Yin</code>, Jiale Zhang and Wenbin Zhang</p> <h3 id="website">Website</h3> <p><a href="https://fairness-lms-tutorial.github.io/">Click</a> to visit our tutorial website.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Tutorial, 34th International Joint Conference on Artificial Intelligence (IJCAI), Montreal, Canada]]></summary></entry><entry><title type="html">Uncertain Boundaries:A Tutorial on Copyright Challenges and Cross-Disciplinary Solutions for Generative AI</title><link href="https://zhipengy.com//blog/2024/ICDMCopyright/" rel="alternate" type="text/html" title="Uncertain Boundaries:A Tutorial on Copyright Challenges and Cross-Disciplinary Solutions for Generative AI"/><published>2024-12-09T00:00:00+00:00</published><updated>2024-12-09T00:00:00+00:00</updated><id>https://zhipengy.com//blog/2024/ICDMCopyright</id><content type="html" xml:base="https://zhipengy.com//blog/2024/ICDMCopyright/"><![CDATA[<h3 id="abstract">Abstract</h3> <p>In the rapidly evolving landscape of generative artificial intelligence (AI), the increasingly pertinent issue of copyright infringement arises as AI advances to generate content from scraped copyrighted data, prompting questions about ownership and protection that impact professionals across various careers. With this in mind, this survey provides an extensive examination of copyright infringement as it pertains to generative AI, aiming to stay abreast of the latest developments and open problems. Specifically, it will first outline methods of detecting copyright infringement in mediums such as text, image, and video. Next, it will delve an exploration of existing techniques aimed at safeguarding copyrighted works from generative models. Furthermore, this survey will discuss resources and tools for users to evaluate copyright violations. Finally, insights into ongoing regulations and proposals for AI will be explored and compared. Through combining these disciplines, the implications of AI-driven content and copyright are thoroughly illustrated and brought into question.</p> <h3 id="authors">Authors</h3> <p>Archer Amon, Zichong Wang, <code class="language-plaintext highlighter-rouge">Zhipeng Yin</code> and Wenbin Zhang</p> <h3 id="website">Website</h3> <p><a href="https://aicopyright-tutorial.github.io/">Click</a> to visit our tutorial website.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Tutorial, 2024 IEEE International Conference on Data Mining (ICDM), Abu Dhabi, UAE]]></summary></entry></feed>